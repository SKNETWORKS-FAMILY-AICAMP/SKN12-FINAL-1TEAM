# ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ì„œ (Database Design)

## ğŸ“‹ ë¬¸ì„œ ì •ë³´
- **í”„ë¡œì íŠ¸ëª…**: ì˜ë£Œì—…ê³„ ì˜ì—…/ê´€ë¦¬ìš© QA ì±—ë´‡ ì‹œìŠ¤í…œ
- **ë¬¸ì„œ ë²„ì „**: 2.0
- **ì‘ì„±ì¼**: 2024-01-01
- **ìµœì¢… ìˆ˜ì •ì¼**: 2024-01-15
- **ê²€í† ì**: ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ì
- **ìŠ¹ì¸ì**: ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸

## ğŸ¯ ë°ì´í„°ë² ì´ìŠ¤ ê°œìš”

### ì„¤ê³„ ëª©í‘œ
- **ì„±ëŠ¥**: ê³ ì† ê²€ìƒ‰ ë° ë¶„ì„ ì²˜ë¦¬
- **í™•ì¥ì„±**: ë°ì´í„° ì¦ê°€ì— ë”°ë¥¸ ìœ ì—°í•œ í™•ì¥
- **ğŸ†• ML ì§€ì›**: ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë° í•™ìŠµ ë°ì´í„° ê´€ë¦¬
- **ë¬´ê²°ì„±**: ë°ì´í„° ì •í•©ì„± ë³´ì¥
- **ë³´ì•ˆ**: ë¯¼ê°í•œ ë°ì´í„° ë³´í˜¸

### ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì„±
- **SQLite**: 7ê°œ ë¶„ë¦¬ëœ ë°ì´í„°ë² ì´ìŠ¤ (ê¸°ì¡´ 6ê°œ + ğŸ†• ML 1ê°œ)
- **File System**: êµ¬ì¡°í™”ëœ íŒŒì¼ ì €ì¥ì†Œ
- **FAISS**: ë²¡í„° ì¸ë±ìŠ¤ ì €ì¥ì†Œ
- **Redis**: ìºì‹œ ë° ì„¸ì…˜ ì €ì¥ì†Œ
- **ğŸ†• MLflow**: ëª¨ë¸ ë° ì‹¤í—˜ ê´€ë¦¬

## ğŸ“Š SQLite ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„

### 1. main.db - ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°ì´í„°ë² ì´ìŠ¤

#### ì‹œìŠ¤í…œ ì„¤ì • í…Œì´ë¸”
```sql
-- ì‹œìŠ¤í…œ ì„¤ì •
CREATE TABLE system_settings (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    key TEXT NOT NULL UNIQUE,
    value TEXT,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ë©”íƒ€ë°ì´í„° í…Œì´ë¸”
CREATE TABLE metadata (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    table_name TEXT NOT NULL,
    record_count INTEGER DEFAULT 0,
    last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    schema_version TEXT DEFAULT '1.0'
);
```

#### ì¸ë±ìŠ¤ ì„¤ì •
```sql
CREATE INDEX idx_system_settings_key ON system_settings(key);
CREATE INDEX idx_metadata_table_name ON metadata(table_name);
```

### 2. users.db - ì‚¬ìš©ì ê´€ë¦¬ ë°ì´í„°ë² ì´ìŠ¤

#### ì‚¬ìš©ì í…Œì´ë¸”
```sql
-- ì‚¬ìš©ì ì •ë³´
CREATE TABLE users (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    username TEXT NOT NULL UNIQUE,
    email TEXT NOT NULL UNIQUE,
    password_hash TEXT NOT NULL,
    full_name TEXT,
    department TEXT,
    role TEXT DEFAULT 'user',
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ì‚¬ìš©ì í”„ë¡œí•„
CREATE TABLE user_profiles (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    phone TEXT,
    avatar_url TEXT,
    preferences TEXT, -- JSON í˜•íƒœ
    timezone TEXT DEFAULT 'Asia/Seoul',
    language TEXT DEFAULT 'ko',
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- ì‚¬ìš©ì ì„¸ì…˜
CREATE TABLE user_sessions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    session_token TEXT NOT NULL UNIQUE,
    expires_at TIMESTAMP NOT NULL,
    ip_address TEXT,
    user_agent TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);
```

#### ì¸ë±ìŠ¤ ì„¤ì •
```sql
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_user_profiles_user_id ON user_profiles(user_id);
CREATE INDEX idx_user_sessions_token ON user_sessions(session_token);
CREATE INDEX idx_user_sessions_expires ON user_sessions(expires_at);
```

### 3. sales.db - ì‹¤ì  ë°ì´í„°ë² ì´ìŠ¤

#### ì‹¤ì  ë°ì´í„° í…Œì´ë¸”
```sql
-- ì‹¤ì  ë°ì´í„°
CREATE TABLE sales_records (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    client_id INTEGER NOT NULL,
    product_id INTEGER,
    sale_amount DECIMAL(15, 2) NOT NULL,
    sale_date DATE NOT NULL,
    quarter TEXT NOT NULL, -- 'Q1', 'Q2', 'Q3', 'Q4'
    year INTEGER NOT NULL,
    region TEXT,
    category TEXT,
    status TEXT DEFAULT 'completed',
    notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ì‹¤ì  ëª©í‘œ
CREATE TABLE sales_targets (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    target_amount DECIMAL(15, 2) NOT NULL,
    target_period TEXT NOT NULL, -- 'monthly', 'quarterly', 'yearly'
    target_date DATE NOT NULL,
    achieved_amount DECIMAL(15, 2) DEFAULT 0,
    achievement_rate DECIMAL(5, 2) DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ğŸ†• ì‹¤ì  ì˜ˆì¸¡ ê¸°ë¡
CREATE TABLE sales_predictions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    client_id INTEGER,
    prediction_type TEXT NOT NULL, -- 'user', 'client', 'product'
    predicted_amount DECIMAL(15, 2) NOT NULL,
    confidence_score DECIMAL(3, 2) NOT NULL,
    prediction_period TEXT NOT NULL, -- 'monthly', 'quarterly', 'yearly'
    prediction_date DATE NOT NULL,
    actual_amount DECIMAL(15, 2),
    accuracy_score DECIMAL(3, 2),
    model_version TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ì œí’ˆ ì •ë³´
CREATE TABLE products (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    category TEXT,
    price DECIMAL(10, 2),
    description TEXT,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### ì¸ë±ìŠ¤ ì„¤ì •
```sql
CREATE INDEX idx_sales_records_user_id ON sales_records(user_id);
CREATE INDEX idx_sales_records_client_id ON sales_records(client_id);
CREATE INDEX idx_sales_records_date ON sales_records(sale_date);
CREATE INDEX idx_sales_records_quarter_year ON sales_records(quarter, year);
CREATE INDEX idx_sales_targets_user_id ON sales_targets(user_id);
CREATE INDEX idx_sales_targets_date ON sales_targets(target_date);
CREATE INDEX idx_sales_predictions_user_id ON sales_predictions(user_id);
CREATE INDEX idx_sales_predictions_date ON sales_predictions(prediction_date);
CREATE INDEX idx_sales_predictions_type ON sales_predictions(prediction_type);
```

### 4. clients.db - ê±°ë˜ì²˜ ê´€ë¦¬ ë°ì´í„°ë² ì´ìŠ¤

#### ê±°ë˜ì²˜ í…Œì´ë¸”
```sql
-- ê±°ë˜ì²˜ ì •ë³´
CREATE TABLE clients (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    business_number TEXT UNIQUE,
    industry TEXT,
    company_size TEXT,
    address TEXT,
    phone TEXT,
    email TEXT,
    website TEXT,
    established_date DATE,
    credit_rating TEXT,
    annual_revenue DECIMAL(15, 2),
    employee_count INTEGER,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ê±°ë˜ì²˜ ë‹´ë‹¹ì
CREATE TABLE client_contacts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    client_id INTEGER NOT NULL,
    name TEXT NOT NULL,
    position TEXT,
    department TEXT,
    phone TEXT,
    email TEXT,
    is_primary BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (client_id) REFERENCES clients(id)
);

-- ê±°ë˜ì²˜ ë¶„ì„ ë°ì´í„°
CREATE TABLE client_analysis (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    client_id INTEGER NOT NULL,
    risk_score DECIMAL(3, 2) NOT NULL,
    grade TEXT NOT NULL, -- 'S', 'A', 'B', 'C'
    profitability_score DECIMAL(3, 2),
    loyalty_score DECIMAL(3, 2),
    growth_potential TEXT,
    analysis_date DATE NOT NULL,
    model_version TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (client_id) REFERENCES clients(id)
);

-- ğŸ†• ê±°ë˜ì²˜ ì˜ˆì¸¡ ë°ì´í„°
CREATE TABLE client_predictions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    client_id INTEGER NOT NULL,
    predicted_grade TEXT NOT NULL,
    confidence_score DECIMAL(3, 2) NOT NULL,
    churn_probability DECIMAL(3, 2),
    growth_prediction DECIMAL(5, 2),
    recommended_actions TEXT, -- JSON í˜•íƒœ
    prediction_date DATE NOT NULL,
    model_version TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (client_id) REFERENCES clients(id)
);
```

#### ì¸ë±ìŠ¤ ì„¤ì •
```sql
CREATE INDEX idx_clients_name ON clients(name);
CREATE INDEX idx_clients_business_number ON clients(business_number);
CREATE INDEX idx_clients_industry ON clients(industry);
CREATE INDEX idx_client_contacts_client_id ON client_contacts(client_id);
CREATE INDEX idx_client_analysis_client_id ON client_analysis(client_id);
CREATE INDEX idx_client_analysis_date ON client_analysis(analysis_date);
CREATE INDEX idx_client_predictions_client_id ON client_predictions(client_id);
CREATE INDEX idx_client_predictions_date ON client_predictions(prediction_date);
```

### 5. news.db - ë‰´ìŠ¤ ë° ì •ë³´ ë°ì´í„°ë² ì´ìŠ¤

#### ë‰´ìŠ¤ í…Œì´ë¸”
```sql
-- ë‰´ìŠ¤ ê¸°ì‚¬
CREATE TABLE news_articles (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT NOT NULL,
    content TEXT,
    summary TEXT,
    url TEXT UNIQUE,
    source TEXT,
    category TEXT,
    published_date DATE,
    relevance_score DECIMAL(3, 2),
    sentiment_score DECIMAL(3, 2),
    keywords TEXT, -- JSON í˜•íƒœ
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ë‰´ìŠ¤ ì¶”ì²œ ê¸°ë¡
CREATE TABLE news_recommendations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    article_id INTEGER NOT NULL,
    recommendation_score DECIMAL(3, 2),
    is_clicked BOOLEAN DEFAULT FALSE,
    clicked_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (article_id) REFERENCES news_articles(id)
);
```

#### ì¸ë±ìŠ¤ ì„¤ì •
```sql
CREATE INDEX idx_news_articles_published_date ON news_articles(published_date);
CREATE INDEX idx_news_articles_category ON news_articles(category);
CREATE INDEX idx_news_recommendations_user_id ON news_recommendations(user_id);
CREATE INDEX idx_news_recommendations_article_id ON news_recommendations(article_id);
```

### 6. cache.db - ìºì‹œ ë°ì´í„°ë² ì´ìŠ¤

#### ìºì‹œ í…Œì´ë¸”
```sql
-- ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ
CREATE TABLE search_cache (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    query_hash TEXT NOT NULL UNIQUE,
    query_text TEXT NOT NULL,
    results TEXT NOT NULL, -- JSON í˜•íƒœ
    result_count INTEGER,
    execution_time REAL,
    expires_at TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ë¶„ì„ ê²°ê³¼ ìºì‹œ
CREATE TABLE analysis_cache (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    cache_key TEXT NOT NULL UNIQUE,
    cache_type TEXT NOT NULL, -- 'report', 'chart', 'prediction'
    data TEXT NOT NULL, -- JSON í˜•íƒœ
    expires_at TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### ì¸ë±ìŠ¤ ì„¤ì •
```sql
CREATE INDEX idx_search_cache_query_hash ON search_cache(query_hash);
CREATE INDEX idx_search_cache_expires ON search_cache(expires_at);
CREATE INDEX idx_analysis_cache_key ON analysis_cache(cache_key);
CREATE INDEX idx_analysis_cache_type ON analysis_cache(cache_type);
CREATE INDEX idx_analysis_cache_expires ON analysis_cache(expires_at);
```

### ğŸ†• 7. ml.db - ë¨¸ì‹ ëŸ¬ë‹ ë°ì´í„°ë² ì´ìŠ¤

#### ML ëª¨ë¸ ê´€ë¦¬ í…Œì´ë¸”
```sql
-- ML ëª¨ë¸ ì •ë³´
CREATE TABLE ml_models (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    model_type TEXT NOT NULL, -- 'time_series', 'classification', 'anomaly'
    version TEXT NOT NULL,
    description TEXT,
    algorithm TEXT, -- 'xgboost', 'prophet', 'isolation_forest'
    hyperparameters TEXT, -- JSON í˜•íƒœ
    training_data_info TEXT, -- JSON í˜•íƒœ
    performance_metrics TEXT, -- JSON í˜•íƒœ
    model_path TEXT,
    mlflow_run_id TEXT,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ëª¨ë¸ í•™ìŠµ ê¸°ë¡
CREATE TABLE model_training_logs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    model_id INTEGER NOT NULL,
    training_start_time TIMESTAMP NOT NULL,
    training_end_time TIMESTAMP,
    training_duration INTEGER, -- ì´ˆ ë‹¨ìœ„
    training_status TEXT NOT NULL, -- 'running', 'completed', 'failed'
    training_data_size INTEGER,
    validation_score DECIMAL(5, 4),
    test_score DECIMAL(5, 4),
    error_message TEXT,
    hyperparameters TEXT, -- JSON í˜•íƒœ
    feature_importance TEXT, -- JSON í˜•íƒœ
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (model_id) REFERENCES ml_models(id)
);

-- íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì •ë³´
CREATE TABLE feature_engineering (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    model_id INTEGER NOT NULL,
    feature_name TEXT NOT NULL,
    feature_type TEXT NOT NULL, -- 'numerical', 'categorical', 'derived'
    transformation TEXT, -- 'standardization', 'normalization', 'encoding'
    importance_score DECIMAL(5, 4),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (model_id) REFERENCES ml_models(id)
);

-- ì˜ˆì¸¡ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
CREATE TABLE prediction_monitoring (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    model_id INTEGER NOT NULL,
    prediction_date DATE NOT NULL,
    prediction_count INTEGER NOT NULL,
    average_confidence DECIMAL(3, 2),
    accuracy_score DECIMAL(3, 2),
    precision_score DECIMAL(3, 2),
    recall_score DECIMAL(3, 2),
    f1_score DECIMAL(3, 2),
    mae DECIMAL(10, 4), -- Mean Absolute Error
    mse DECIMAL(10, 4), -- Mean Squared Error
    rmse DECIMAL(10, 4), -- Root Mean Squared Error
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (model_id) REFERENCES ml_models(id)
);

-- ë°ì´í„° ë“œë¦¬í”„íŠ¸ ê°ì§€
CREATE TABLE data_drift_detection (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    model_id INTEGER NOT NULL,
    feature_name TEXT NOT NULL,
    drift_score DECIMAL(5, 4) NOT NULL,
    threshold DECIMAL(5, 4) NOT NULL,
    is_drift_detected BOOLEAN DEFAULT FALSE,
    detection_date DATE NOT NULL,
    reference_period TEXT, -- 'last_week', 'last_month'
    drift_type TEXT, -- 'covariate_shift', 'concept_drift'
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (model_id) REFERENCES ml_models(id)
);

-- ì¶”ì²œ ì—”ì§„ ë°ì´í„°
CREATE TABLE recommendation_rules (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    rule_name TEXT NOT NULL,
    rule_type TEXT NOT NULL, -- 'performance', 'client', 'product'
    condition_sql TEXT NOT NULL,
    recommendation_text TEXT NOT NULL,
    priority INTEGER DEFAULT 1,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### ì¸ë±ìŠ¤ ì„¤ì •
```sql
CREATE INDEX idx_ml_models_name ON ml_models(name);
CREATE INDEX idx_ml_models_type ON ml_models(model_type);
CREATE INDEX idx_ml_models_version ON ml_models(version);
CREATE INDEX idx_model_training_logs_model_id ON model_training_logs(model_id);
CREATE INDEX idx_model_training_logs_status ON model_training_logs(training_status);
CREATE INDEX idx_feature_engineering_model_id ON feature_engineering(model_id);
CREATE INDEX idx_prediction_monitoring_model_id ON prediction_monitoring(model_id);
CREATE INDEX idx_prediction_monitoring_date ON prediction_monitoring(prediction_date);
CREATE INDEX idx_data_drift_detection_model_id ON data_drift_detection(model_id);
CREATE INDEX idx_data_drift_detection_date ON data_drift_detection(detection_date);
CREATE INDEX idx_recommendation_rules_type ON recommendation_rules(rule_type);
```

## ğŸ“ íŒŒì¼ ì‹œìŠ¤í…œ ì„¤ê³„

### ì „ì²´ íŒŒì¼ êµ¬ì¡°
```
data/
â”œâ”€â”€ files/
â”‚   â”œâ”€â”€ documents/                  # ì—…ë¡œë“œ ë¬¸ì„œ
â”‚   â”‚   â”œâ”€â”€ contracts/              # ê³„ì•½ì„œ
â”‚   â”‚   â”œâ”€â”€ reports/                # ë³´ê³ ì„œ
â”‚   â”‚   â”œâ”€â”€ manuals/                # ë§¤ë‰´ì–¼
â”‚   â”‚   â””â”€â”€ regulations/            # ê·œì •ì§‘
â”‚   â”œâ”€â”€ uploads/                    # ì‚¬ìš©ì ì—…ë¡œë“œ
â”‚   â”‚   â”œâ”€â”€ temp/                   # ì„ì‹œ íŒŒì¼
â”‚   â”‚   â””â”€â”€ processed/              # ì²˜ë¦¬ëœ íŒŒì¼
â”‚   â”œâ”€â”€ conversations/              # ëŒ€í™” ê¸°ë¡
â”‚   â”‚   â”œâ”€â”€ audio/                  # ìŒì„± íŒŒì¼
â”‚   â”‚   â”œâ”€â”€ transcripts/            # í…ìŠ¤íŠ¸ ë³€í™˜
â”‚   â”‚   â””â”€â”€ analysis/               # ë¶„ì„ ê²°ê³¼
â”‚   â””â”€â”€ wiki/                       # ìœ„í‚¤ ë°ì´í„°
â”‚       â”œâ”€â”€ articles/               # ìœ„í‚¤ ë¬¸ì„œ
â”‚       â”œâ”€â”€ images/                 # ì´ë¯¸ì§€ íŒŒì¼
â”‚       â””â”€â”€ attachments/            # ì²¨ë¶€ íŒŒì¼
â”œâ”€â”€ ğŸ†• ml_data/                     # ML ë°ì´í„°
â”‚   â”œâ”€â”€ raw/                        # ì›ì‹œ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ sales_data.csv
â”‚   â”‚   â”œâ”€â”€ client_data.csv
â”‚   â”‚   â””â”€â”€ user_data.csv
â”‚   â”œâ”€â”€ processed/                  # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ targets/
â”‚   â”‚   â””â”€â”€ splits/
â”‚   â”œâ”€â”€ features/                   # íŠ¹ì„± ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ time_series_features.pkl
â”‚   â”‚   â”œâ”€â”€ categorical_features.pkl
â”‚   â”‚   â””â”€â”€ derived_features.pkl
â”‚   â””â”€â”€ predictions/                # ì˜ˆì¸¡ ê²°ê³¼
â”‚       â”œâ”€â”€ daily/
â”‚       â”œâ”€â”€ weekly/
â”‚       â””â”€â”€ monthly/
```

### íŒŒì¼ ë„¤ì´ë° ê·œì¹™
```
documents/
â”œâ”€â”€ contracts/
â”‚   â””â”€â”€ {client_id}_{contract_type}_{date}.pdf
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ {report_type}_{period}_{date}.pdf
â””â”€â”€ manuals/
    â””â”€â”€ {category}_{version}_{date}.pdf

ğŸ†• ml_data/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ {data_type}_{date_range}.csv
â”œâ”€â”€ processed/
â”‚   â””â”€â”€ {data_type}_{processing_version}_{date}.pkl
â””â”€â”€ predictions/
    â””â”€â”€ {model_type}_{prediction_date}_{version}.json
```

## ğŸ” FAISS ë²¡í„° ì¸ë±ìŠ¤ ì„¤ê³„

### ì¸ë±ìŠ¤ êµ¬ì¡°
```
faiss_indexes/
â”œâ”€â”€ documents_index.faiss           # ë¬¸ì„œ ë²¡í„° ì¸ë±ìŠ¤
â”œâ”€â”€ wiki_index.faiss                # ìœ„í‚¤ ë²¡í„° ì¸ë±ìŠ¤
â”œâ”€â”€ conversations_index.faiss       # ëŒ€í™” ë²¡í„° ì¸ë±ìŠ¤
â”œâ”€â”€ ğŸ†• ml_features_index.faiss      # ML íŠ¹ì„± ë²¡í„° ì¸ë±ìŠ¤
â””â”€â”€ metadata/
    â”œâ”€â”€ documents_metadata.json     # ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
    â”œâ”€â”€ wiki_metadata.json          # ìœ„í‚¤ ë©”íƒ€ë°ì´í„°
    â”œâ”€â”€ conversations_metadata.json # ëŒ€í™” ë©”íƒ€ë°ì´í„°
    â””â”€â”€ ğŸ†• ml_features_metadata.json # ML íŠ¹ì„± ë©”íƒ€ë°ì´í„°
```

### ë²¡í„° ì¸ë±ìŠ¤ ì„¤ì •
```python
# FAISS ì¸ë±ìŠ¤ ì„¤ì •
class FAISSIndexConfig:
    DOCUMENT_INDEX = {
        'dimension': 1024,  # KURE-v1 ì„ë² ë”© ì°¨ì›
        'index_type': 'HNSW',
        'metric': 'cosine',
        'parameters': {
            'M': 16,
            'efConstruction': 200,
            'efSearch': 50
        }
    }
    
    # ğŸ†• ML íŠ¹ì„± ì¸ë±ìŠ¤ ì„¤ì •
    ML_FEATURES_INDEX = {
        'dimension': 512,
        'index_type': 'IVF',
        'metric': 'euclidean',
        'parameters': {
            'nlist': 100,
            'nprobe': 10
        }
    }
```

## ğŸ“Š Redis ìºì‹œ ì„¤ê³„

### ìºì‹œ í‚¤ ë„¤ì´ë° ê·œì¹™
```
search:query:{query_hash}           # ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ
analysis:report:{report_id}         # ë¶„ì„ ë³´ê³ ì„œ ìºì‹œ
prediction:user:{user_id}:{period}  # ì‚¬ìš©ì ì˜ˆì¸¡ ìºì‹œ
prediction:client:{client_id}:{period} # ê±°ë˜ì²˜ ì˜ˆì¸¡ ìºì‹œ
model:performance:{model_id}:{date} # ëª¨ë¸ ì„±ëŠ¥ ìºì‹œ
session:user:{user_id}              # ì‚¬ìš©ì ì„¸ì…˜
```

### ìºì‹œ ë§Œë£Œ ì‹œê°„
```python
CACHE_EXPIRY = {
    'search_results': 3600,      # 1ì‹œê°„
    'analysis_reports': 86400,   # 24ì‹œê°„
    'ml_predictions': 21600,     # 6ì‹œê°„
    'model_performance': 3600,   # 1ì‹œê°„
    'user_sessions': 3600,       # 1ì‹œê°„
    'news_articles': 1800        # 30ë¶„
}
```

## ğŸ”„ MLflow ëª¨ë¸ ì €ì¥ì†Œ ì„¤ê³„

### MLflow ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
mlflow/
â”œâ”€â”€ artifacts/                      # ëª¨ë¸ ì•„í‹°íŒ©íŠ¸
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ time_series/
â”‚   â”‚   â”‚   â”œâ”€â”€ prophet_sales_v1.0/
â”‚   â”‚   â”‚   â”œâ”€â”€ xgboost_client_v1.0/
â”‚   â”‚   â”‚   â””â”€â”€ lstm_trend_v1.0/
â”‚   â”‚   â”œâ”€â”€ classification/
â”‚   â”‚   â”‚   â”œâ”€â”€ client_grade_v1.0/
â”‚   â”‚   â”‚   â””â”€â”€ performance_class_v1.0/
â”‚   â”‚   â””â”€â”€ anomaly/
â”‚   â”‚       â””â”€â”€ isolation_forest_v1.0/
â”‚   â”œâ”€â”€ datasets/                   # í•™ìŠµ ë°ì´í„°ì…‹
â”‚   â”œâ”€â”€ preprocessors/              # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
â”‚   â””â”€â”€ evaluation/                 # í‰ê°€ ê²°ê³¼
â”œâ”€â”€ experiments/                    # ì‹¤í—˜ ê¸°ë¡
â”‚   â”œâ”€â”€ sales_prediction/
â”‚   â”œâ”€â”€ client_classification/
â”‚   â””â”€â”€ anomaly_detection/
â”œâ”€â”€ models/                         # ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
â”‚   â”œâ”€â”€ production/
â”‚   â”œâ”€â”€ staging/
â”‚   â””â”€â”€ archived/
â””â”€â”€ runs/                           # ì‹¤í–‰ ê¸°ë¡
    â”œâ”€â”€ {run_id}/
    â””â”€â”€ metrics/
```

### ëª¨ë¸ ë©”íƒ€ë°ì´í„° êµ¬ì¡°
```json
{
  "model_info": {
    "name": "sales_prediction_xgboost",
    "version": "1.0",
    "algorithm": "XGBoost",
    "framework": "xgboost",
    "created_at": "2024-01-15T10:00:00Z"
  },
  "training_info": {
    "dataset_size": 10000,
    "features": ["sales_amount", "client_grade", "season"],
    "target": "next_month_sales",
    "validation_method": "time_series_split"
  },
  "performance_metrics": {
    "mae": 1250.5,
    "mse": 2500000.0,
    "rmse": 1581.1,
    "r2_score": 0.85,
    "mape": 0.12
  },
  "hyperparameters": {
    "n_estimators": 100,
    "max_depth": 6,
    "learning_rate": 0.1,
    "subsample": 0.8
  }
}
```

## ğŸ”„ ë°ì´í„° í”Œë¡œìš° ì„¤ê³„

### ì „ì²´ ë°ì´í„° í”Œë¡œìš°
```mermaid
graph TD
    A[ì‚¬ìš©ì ì…ë ¥] --> B[Django Gateway]
    B --> C[FastAPI ì„œë¹„ìŠ¤]
    C --> D[SQLite ë°ì´í„°ë² ì´ìŠ¤]
    C --> E[íŒŒì¼ ì‹œìŠ¤í…œ]
    C --> F[FAISS ë²¡í„° ì¸ë±ìŠ¤]
    C --> G[Redis ìºì‹œ]
    C --> H[ğŸ†• MLflow ëª¨ë¸]
    
    I[ğŸ†• ML íŒŒì´í”„ë¼ì¸] --> J[ë°ì´í„° ìˆ˜ì§‘]
    J --> K[ì „ì²˜ë¦¬]
    K --> L[íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§]
    L --> M[ëª¨ë¸ í•™ìŠµ]
    M --> N[ëª¨ë¸ í‰ê°€]
    N --> O[ëª¨ë¸ ë“±ë¡]
    O --> H
    
    H --> P[ì˜ˆì¸¡ ì„œë¹„ìŠ¤]
    P --> Q[ì˜ˆì¸¡ ê²°ê³¼]
    Q --> C
```

### ğŸ†• ML ë°ì´í„° í”Œë¡œìš°
```mermaid
graph TD
    A[Raw Data] --> B[Data Validation]
    B --> C[Data Preprocessing]
    C --> D[Feature Engineering]
    D --> E[Model Training]
    E --> F[Model Evaluation]
    F --> G[Model Registry]
    G --> H[Model Serving]
    H --> I[Prediction API]
    I --> J[Result Storage]
    J --> K[Performance Monitoring]
    K --> L[Drift Detection]
    L --> M[Model Retraining]
    M --> E
```

## ğŸ”§ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”

### SQLite ìµœì í™” ì„¤ì •
```sql
-- ì„±ëŠ¥ ìµœì í™” ì„¤ì •
PRAGMA journal_mode = WAL;
PRAGMA synchronous = NORMAL;
PRAGMA cache_size = 10000;
PRAGMA temp_store = MEMORY;
PRAGMA mmap_size = 268435456; -- 256MB
```

### ğŸ†• ML ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
```sql
-- ML ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
PRAGMA journal_mode = WAL;
PRAGMA synchronous = NORMAL;
PRAGMA cache_size = 50000;      -- ë” í° ìºì‹œ í¬ê¸°
PRAGMA temp_store = MEMORY;
PRAGMA mmap_size = 1073741824;  -- 1GB
```

### ì¸ë±ìŠ¤ ìµœì í™” ì „ëµ
```sql
-- ë³µí•© ì¸ë±ìŠ¤ ì„¤ê³„
CREATE INDEX idx_sales_user_date ON sales_records(user_id, sale_date);
CREATE INDEX idx_client_analysis_grade_date ON client_analysis(grade, analysis_date);
CREATE INDEX idx_predictions_type_date ON sales_predictions(prediction_type, prediction_date);

-- ğŸ†• ML ê´€ë ¨ ë³µí•© ì¸ë±ìŠ¤
CREATE INDEX idx_ml_models_type_active ON ml_models(model_type, is_active);
CREATE INDEX idx_training_logs_model_status ON model_training_logs(model_id, training_status);
CREATE INDEX idx_prediction_monitoring_model_date ON prediction_monitoring(model_id, prediction_date);
```

## ğŸ” ë³´ì•ˆ ì„¤ê³„

### ë°ì´í„° ì•”í˜¸í™”
```python
# ë¯¼ê°í•œ ë°ì´í„° ì•”í˜¸í™”
class DataEncryption:
    AES_KEY_SIZE = 256
    ENCRYPTION_FIELDS = [
        'users.password_hash',
        'clients.business_number',
        'sales_records.notes',
        'ml_models.hyperparameters'  # ğŸ†• ML ëª¨ë¸ ë³´ì•ˆ
    ]
```

### ì ‘ê·¼ ê¶Œí•œ ê´€ë¦¬
```sql
-- ì‚¬ìš©ì ê¶Œí•œ í…Œì´ë¸”
CREATE TABLE user_permissions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    resource_type TEXT NOT NULL, -- 'sales', 'clients', 'ml_models'
    permission_level TEXT NOT NULL, -- 'read', 'write', 'admin'
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- ğŸ†• ML ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œ
CREATE TABLE ml_model_permissions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    model_id INTEGER NOT NULL,
    permission_type TEXT NOT NULL, -- 'view', 'predict', 'train', 'manage'
    granted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id),
    FOREIGN KEY (model_id) REFERENCES ml_models(id)
);
```

## ğŸ”„ ë°±ì—… ë° ë³µì› ì „ëµ

### ë°±ì—… ìŠ¤ì¼€ì¤„
```bash
# ì¼ì¼ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash
DATE=$(date +%Y%m%d)
BACKUP_DIR="/backup/${DATE}"

# SQLite ë°±ì—…
sqlite3 data/sqlite/main.db ".backup ${BACKUP_DIR}/main_${DATE}.db"
sqlite3 data/sqlite/users.db ".backup ${BACKUP_DIR}/users_${DATE}.db"
sqlite3 data/sqlite/sales.db ".backup ${BACKUP_DIR}/sales_${DATE}.db"
sqlite3 data/sqlite/clients.db ".backup ${BACKUP_DIR}/clients_${DATE}.db"
sqlite3 data/sqlite/news.db ".backup ${BACKUP_DIR}/news_${DATE}.db"
sqlite3 data/sqlite/cache.db ".backup ${BACKUP_DIR}/cache_${DATE}.db"
sqlite3 data/sqlite/ml.db ".backup ${BACKUP_DIR}/ml_${DATE}.db"  # ğŸ†• ML DB ë°±ì—…

# íŒŒì¼ ì‹œìŠ¤í…œ ë°±ì—…
tar -czf ${BACKUP_DIR}/files_${DATE}.tar.gz data/files/
tar -czf ${BACKUP_DIR}/ml_data_${DATE}.tar.gz data/ml_data/  # ğŸ†• ML ë°ì´í„° ë°±ì—…

# FAISS ì¸ë±ìŠ¤ ë°±ì—…
tar -czf ${BACKUP_DIR}/faiss_${DATE}.tar.gz data/faiss_indexes/

# ğŸ†• MLflow ë°±ì—…
tar -czf ${BACKUP_DIR}/mlflow_${DATE}.tar.gz mlflow/
```

### ğŸ†• ML ëª¨ë¸ ë°±ì—… ì „ëµ
```python
class MLModelBackup:
    def __init__(self):
        self.mlflow_client = MlflowClient()
    
    def backup_model(self, model_name, version):
        # ëª¨ë¸ ë©”íƒ€ë°ì´í„° ë°±ì—…
        model_version = self.mlflow_client.get_model_version(model_name, version)
        
        # ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ë°±ì—…
        model_uri = f"models:/{model_name}/{version}"
        local_path = f"backup/models/{model_name}_v{version}"
        
        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì••ì¶•
        mlflow.artifacts.download_artifacts(model_uri, dst_path=local_path)
        
        return local_path
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­

### ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```sql
-- ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸° ëª¨ë‹ˆí„°ë§
SELECT name, 
       page_count * page_size / 1024 / 1024 as size_mb
FROM pragma_database_list(), pragma_page_count(), pragma_page_size();

-- ì¸ë±ìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
SELECT name, sql 
FROM sqlite_master 
WHERE type = 'index' AND tbl_name = 'sales_records';
```

### ğŸ†• ML ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
```python
class MLDataQualityMonitor:
    def __init__(self):
        self.quality_metrics = {}
    
    def monitor_data_quality(self, table_name):
        metrics = {
            'completeness': self.calculate_completeness(table_name),
            'accuracy': self.calculate_accuracy(table_name),
            'consistency': self.calculate_consistency(table_name),
            'timeliness': self.calculate_timeliness(table_name)
        }
        return metrics
    
    def detect_anomalies(self, data):
        # ë°ì´í„° ì´ìƒì¹˜ ê°ì§€
        anomalies = []
        for column in data.columns:
            if data[column].dtype in ['int64', 'float64']:
                q1 = data[column].quantile(0.25)
                q3 = data[column].quantile(0.75)
                iqr = q3 - q1
                lower_bound = q1 - 1.5 * iqr
                upper_bound = q3 + 1.5 * iqr
                
                anomalies.extend(data[(data[column] < lower_bound) | 
                                    (data[column] > upper_bound)].index.tolist())
        
        return anomalies
```

## ğŸ“ ë¬¸ì„œ ìŠ¹ì¸

### ê²€í†  ì´ë ¥
- **v1.0** (2024-01-01): ì´ˆê¸° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„
- **v2.0** (2024-01-15): ML ë°ì´í„°ë² ì´ìŠ¤ ë° MLflow í†µí•©

### ìŠ¹ì¸ì
- **ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ì**: ê¹€ë””ë¹„ (2024-01-15)
- **ML ì—”ì§€ë‹ˆì–´**: ë°•ë¨¸ì‹  (2024-01-15)
- **ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸**: ì´ì‹œìŠ¤í…œ (2024-01-15)

### ë‹¤ìŒ ê²€í†  ì˜ˆì •ì¼
- **2024-02-15**: ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ë° ML ë°ì´í„° í’ˆì§ˆ ê²€í† 

---
*ì´ ë¬¸ì„œëŠ” ì‹œìŠ¤í…œ ê°œë°œ ì§„í–‰ì— ë”°ë¼ ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.* 